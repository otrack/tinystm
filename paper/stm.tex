\section{Algorithm}
\labsection{stm}

In this section, we present a software transactional memory to implement $\SPSER$.
This construction is disjoint-access parallel and weakly-progressive, i.e., it aborts a transaction only if it encounters a concurrent conflicting transaction 
This section gives an overview of the algorithm, present its internals and justify some design choices.
A correctness proofs follows.

\subsection{Overview}
\labsection{stm:overview}

\refalg{stm} depicts the pseudo-code of our construction of the STM interface at some process $p$.
Our design follow the general design of the lazy snapshot algorithm (LSA) of \citet{FelberFMR10}, replacing the central clock with a more flexible mechanism.
\refalg{stm} employs a deferred update schema that consists in two steps.
A transaction first executes optimistically, buffering its updates.
Then at commit time the transaction is certified and, provided it commits, its updates are applied to the shared memory.

During the execution of a transaction, process $p$ checks that the objects accessed so far did not change.
Similarly to LSA, this check is lazily executed.
\refalg{stm} executes it only when a shared object appears to have been recently updated, or when the transaction terminates.

\subsection{Tracking Time}
\labsection{stm:time}

\refalg{stm} tracks time to compute how concurrent transactions interleave during an execution.
To this end, the algorithm makes use of logical clocks.
We model the interface of a \emph{logical clock} with two operations: $\cread$ returns a value in $\naturalSet$, and $\cadv(v \in \naturalSet)$ updates the clock with value $v$.
The sequential specification of a logical clock guarantees a single property, that the time flows forward:
\begin{inparaenum}
\item[\emph{(Time monoticity)}]
  A read operation always returns at least the greatest value to which the clock advanced so far.
  Formally, for every history $h$, $(\responseAny{\cread}{v} \in h) \implies (v \geq \max{(\{u : \cadv(u) \hb_h \cread \} \union \{0\})})$.
\end{inparaenum}

\refalg{stm} associates logical clocks with both processes and transactions.
To retrieve the clock associated with some object $i$, the algorithm uses function $\clockOf{i}$.
Notice that in the pseudo-code, when it is clear from the context, we write $\clockOf{i}$ as a shorthand for $\clockOf{i}.\mathit{read}()$.

The clock associated with a transaction is always local (\refline{stm:var:1}).
In the case of a process, it might be shared or not (\refline{stm:var:2}).
The flexibility of our design comes from this locality choice for \clockOf{p}.
When the clock is shared, it is linearizable.
To implement an (obstruction-free) linearizable clock we employ the following common approach:
\begin{construction}
  Let $x$ be a shared register initialized to $0$.
  When $\cread$ is called, we return the value stored in $x$.
  Upon executing $\cadv(v)$, we fetch the value stored in $x$, say $u$.
  If $v > u$ holds, we execute a compare-and-swap to replace $u$ with $v$; 
  otherwise the operation returns.
  If the compare-and-swap fails, the previous steps are retried.
\end{construction}

\input{algorithms/stm.tex}

\subsection{Details}
\labsection{stm:details}

In \refalg{stm}, each object $x$ has a \emph{location} in the shared memory, denoted $\locationOf{x}$.
This location stores a pair $(t,d)$, where $t \in \naturalSet$ is a \emph{timestamp}, and $d$ is the actual content of $x$ as seen by transactions.
For simplicity, we shall name hereafter a pair $(t,d)$ a \emph{version} of object $x$.
Since the location of object $x$ is unique, a single version of object $x$ may exist at a time in the memory.
As usual, we asume some transaction $\transInit$ that intializes for every object $x$ the location $\locationOf{x}$ to $(0,\bot)$.
Furthermore, we consider that each object $x$ is atomic.

\refalg{stm} associates each object with a lock.
To manipulate the lock-related functions of object $x$, 
a process $p$ employs appropriately the functions $\lock{x}$, $\isLocked{x}$ and $\unlock{x}$.

For every transaction $T$ submitted to the system, \refalg{stm} maintains three local data structures:
\begin{inparaenum}[]
\item $\clockOf{T}$ is the logical clock of transaction $T$,
\item $\readSetOf{T}$ is a map that contains its \emph{read set}, and 
\item $\writeSetOf{T}$ is another map that stores the \emph{write set} of $T$.
\end{inparaenum}
\refalg{stm} updates incrementally $\readSetOf{T}$ and $\writeSetOf{T}$ over the course of the execution.
The read set serves to check that the view of the shared memory, or \emph{snpashot}, seen by the transaction is consistent.
The write set buffers updates.
In detail, the execution of a transaction $T$ proceeds as follows.

\begin{itemize}
\item[-] %
  When $T$ starts its execution, \refalg{stm} initializes $\clockOf{T}$ to the value of $\clockOf{p}$, then both $\readSetOf{T}$ and $\writeSetOf{T}$ to $\emptySet$ (\reflines{stm:start:1}{stm:start:3}).
\item[-] %
  When $T$ accesses a shared object $x$, if $x$ was previously written, its value is returned (\refline{stm:read:1}).
  Otherwise, \refalg{stm} fetches atomically the version $(d,t)$, as seen in location $\locationOf{x}$.
  Then, the algorithm checks that 
  \begin{inparaenum}
  \item no lock is held on $x$, and 
  \item in case $x$ was previously accessed, that $T$ observes the same version.
  \end{inparaenum}
  If one of these two conditions fails, \refalg{stm} aborts transaction $T$ (\refline{stm:read:5}).
  The algorithm then checks that the timestamp $t$ associated to the content $d$ is smaller than the clock of $T$.
  In case this does not hold (\refline{stm:read:6}), \refalg{stm} tries extending the snapshot of $T$ by calling function $\stmExtend{}$.
  This function returns $\true$ when the versions previously read by $T$ are still valid.
  In which case, $\clockOf{T}$ is updated to the value $t$.
  If \refalg{stm} succeeds in extending (if needed) the snapshot of $T$, $d$ is returned and the read set of $T$ updated accordingly;
  otherwise transaction $T$ is aborted (\refline{stm:read:7}).
\item[-] %
  Upon executing a write request on behalf of $T$ to some object $x$, \refalg{stm} takes the lock associated with $x$ (\refline{stm:write:1}), and in case of success, it buffers the update value $d$ in $\writeSetOf{T}$ (\refline{stm:write:6}).
  The timestamp $t$ of $x$ at the time \refalg{stm} takes the lock serves two purposes.
  First, \refalg{stm} checks that $t$ is lower than the current clock of $T$, and if not $T$ is extended (\refline{stm:write:4}).
  Second, it is saved in \writeSetOf{T} to ensure that at commit time the timestamp of the version of $x$ written by $T$ is greater than $t$.
\item[-] %
  When $T$ requests to commit, \refalg{stm} certifies the read set by calling function $\stmExtend{}$ with the clock of $T$ (\refline{stm:try:1}).
  If this test succeeds, transaction $T$ commits (\reflines{stm:commit:1}{stm:commit:6}).
  In such a case, \clockOf{T} ticks to reach its final value (\refline{stm:commit:1}).
  By construction, this value is greater than the clock of process $p$ at the time transaction $T$ started (\refline{stm:start:1}), as well as all the timestamps of all the versions read or written by $T$ (\reflinestwo{stm:read:5}{stm:write:4}).
  \refalg{stm} updates the clock of $p$ with the final value of \clockOf{T} (\refline{stm:commit:2}), then it updates the items written by $T$ with their novel versions (\refline{stm:commit:4}).
\end{itemize}

\refalg{stm} replaces the global clock usually employed in STM architectures with a locality-aware clock.
When \clockOf{p} is local to each process, \refalg{stm} ensures strict disjoint access parallelism (DAP) \cite{Attiya2015}.
More formally, this means that two transaction access concurrently a bae object of the implementation only if they contend on some shared object.
Provided the workload is parallel, DAP ensures the scalability of \refalg{stm}.
We assess empirically this claim in \refsection{evaluation}.

On the other hand, if processes need to synchronize too often, maintaining consistency among the various clocks is expensive.
In this situation, it might be of interest to find a compromise between the cost of cache coherency and the need for synchronization.
For instance, in a NUMA architecture, \refalg{stm} may assign a common clock per hardware socket.
Upon a call to $\clockOf{p}$, the algortihm returns the clock defined for the socket in which the processor executing process $p$ resides.

\subsection{Guarantees}
\labsection{stm:guarantees}

In this section, we prove the different properties \refalg{stm} provides.
First, we show that our STM design is weakly progressive and stricter serializable.
Then, we prove that, when $\clockOf{p}$ is local, \refalg{stm} is disjoint-access parallel.

\paragraph{(Weak-progress)}
A transaction executes under \emph{weak progressiveness} \cite{Guerraoui:2009}, or equivalently it is \emph{weakly progressive}, when it aborts only if it encounters a conflicting transaction.
By extension, an STM is weakly progressive when it only produces histories during which transactions are weakly-progressive.
We prove that this property holds for \refalg{stm}.

In \refalg{stm}, a transaction $T$ aborts either at \refline{stm:read:5}, \ref{line:alg:stm:read:7}, \ref{line:alg:stm:write:2}, \ref{line:alg:stm:write:5}, or \ref{line:alg:stm:try:2}.
We observe that in such a case either $T$ observes an item $x$ locked, or that the timestamp associated with $x$ has changed.
It follows that if $T$ aborts then it observes a conflict with a concurrent transaction.
From which we deduce that it is executing under weak progressiveness.

\paragraph{(Stricter serializability)}
Consider some run $\run$ of \refalg{stm}, and let $h$ be the history produced in \run.
At the light of its pseudo-code, every function defined in \refalg{stm} is wait-free.
As a consequence, we may consider without lack of generality that $h$ is complete, i.e., every transaction executed in $h$ terminates with either a commit or an abort event.
In what follows, we define that $\ll_h$ as the order in which writes to the object locations are linearized in $\rho$.
We first prove that $<$ is acyclic for this definition of $\ll_h$.
Then, we show that, if a transaction does not exhibit any unfair binding, then it observes a strictly consistent snapshot.
For some transaction, we shall note $\clockOf{T_i}_f$ the final value of $\clockOf{T}$.

\begin{proposition}
  \labprop{stm:1}
  Consider two transactions $T_i$ and $T_{j \neq i}$ in $h$.
  If either $T_i \depends T_j$ or  $x_j \ll_h x_i$ holds, then $\clockOf{T_i}_f \geq \clockOf{T_j}_f$ is true.
  In addition, if transaction $T_i$ commits then the ordering is strict, i.e., $\clockOf{T_i}_f > \clockOf{T_j}_f$.
\end{proposition}

\begin{proof}

  In each of the two cases, we prove that $\clockOf{T_i}_f \geq \clockOf{T_i}_f$ holds before transaction $T_i$ commits.
  \begin{itemize}
  \item[($T_i \depends T_j$)]
    Let $x$ be an object such that $r_i(x_j)$ occurs in $h$.
    Since transaction $T_i$ reads version $x_j$, transaction $T_j$ commits.
    We observe that $T_j$ writes version $x_j$ together with $\clockOf{T_j}_f$ at $\locationOf{x}$ when it commits (\refline{stm:commit:4}).
    As a consequence, when transaction $T_i$ returns version $x_i$ at \refline{stm:read:9}, it assigns $\clockOf{T_j}_f$ to $t$ before at \refline{stm:read:2}.
    The condition at \refline{stm:read:6} implies that either $\clockOf{T_i} \geq t$ holds, or a call to $\stmExtend{T_i,t}$ occurs.
    In the latter case, transactino $T_i$ executes \refline{stm:extend:5}, advancing its clock up to the value of $t$.
  \item[($x_j \ll_h x_i$)]
    By definition, relation $\ll_h$ forms a total order over all versions of $x$.
    Thus, we may reason by induction, considering that $x_i$ is immediately after $x_j$ in the order $\ll_h$.
    When $T_j$ returns from $w_j(x_j)$ at \refline{stm:write:6}, it holds a lock on $x$.
    This lock is released at \refline{stm:commit:5} after writing to $\locationOf{x}$.
    As $\ll_h$ follows the linearization order, $T_i$ executes \refline{stm:write:1} after $T_j$ wrote $(x_j, \clockOf{T_j}_f)$ to $\locationOf{x}$.
    Location $\locationOf{x}$ is not updated between $x_j$ and $x_i$.
    Hence, after$T_i$ executes \refline{stm:write:4}, $\clockOf{T_i} \geq \clockOf{T_j}$ holds.
  \end{itemize}
  Since a clock is monotonic, the relation holds forever.
  Then, if transaction $T_i$ commits, it must executes \refline{stm:commit:1}, leading to $\clockOf{T_i}_f > \clockOf{T_i}_f$.
\end{proof}

\begin{proposition}
  \labprop{stm:2}
  Consider two transactions $T_i$ and $T_{j \neq i}$ in $\committed{h}$ such that $T_i < T_j$.
  Then, transaction $T_i$ invokes $\stmCommitFunction$ before transaction $T_j$ in $h$.
\end{proposition}

\begin{proof}
  Assume that $T_i$ and $T_j$ conflict of some object $x$.
  We examine in order each of the four cases defining relation $<$.
  \begin{compactitem}
  \item ($T_i \hb_h T_j$)\\
    This case is immediate.
  \item ($\exists x : r_j(x_i) \in h$)\\
    Before committing, $T_j$ invokes \stmExtendFunction at \refline{stm:try:1}.
    Since $T_j$ commits in $h$, it should retrieve $(x_i,\msgAny)$ from $\locationOf{x}$ when executing \refline{stm:extend:2}.
    Hence, transaction $T_i$ has already exeecuted \refline{stm:commit:4} on object $x$.
    It follows that $T_i$ invokes $\stmCommitFunction$ before transaction $T_j$ in history $h$.
  \item ($\exists x : x_i \ll_h x_j$)\\
    By definition of $\ll_h$, the write of version $x_i$ is linearized before the write of version $x_j$ in $\rho$.
    After $T_i$ returns from $w_i(x_i)$, it owns a lock on object $x$ (\refline{stm:commit:4}).
    The object is then unlocked by transaction $T_i$ at \refline{stm:commit:5}.
    As a consequence, transaction $T_i$ takes a lock on object $x$ after $T_i$ invokes operation $\stmCommitFunction$.
    From which it follows that the claim holds.
  \item ($\exists x, T_k : x_k \ll_x x_j \land r_i(x_k)$)\\
    For the sake of contradiction, assume that $T_j$ invokes $\stmCommitFunction$ before $T_i$.
    When $T_j$ invokes $\stmCommitFunction$, it holds a lock on $x$.
    This lock is released at \refline{stm:commit:5} after version $x_j$ is written at location $\locationOf{x}$.
    %
    Then, consider the time at which $T_i$ invokes $\stmTryCommitFunction$.
    The call at \refline{stm:try:1} leads to fetching $\locationOf{x}$ at \refline{stm:extend:2}.
    Since $T_i$ reads version $x_k$ in $h$, a pair $(\clockOf{T_k}_f, x_k)$ is in $\readSetOf{T_i}$.
    From the definition of $\ll_h$ the write of $(\clockOf{T_k}_f, x_k)$ takes place before the write of version $(\clockOf{T_j}_f,x_j)$ in $\rho$.
    Hence, $\locationOf{x}$ does not contain anymore $(\clockOf{T_k}_f, x_k)$
    Applying \refprop{stm:1}, $T_i$ executes \refline{stm:extend:4} and aborts at \refline{stm:try:3}.
    Contradiction.
  \end{compactitem}
  
\end{proof}

\begin{proposition}
  \labprop{stm:3}
  History $h$ does not exhibit any RC-anti-dependencies ($h \notin \RCAD$)
\end{proposition}

\begin{proof}

  Consider $T_i$, $T_j$ and $T_k$ such that $r_i(x_k), w_j(x_j) \in h$, $x_k \ll_h x_j$ and $T_j$ commits before $T_i$.
  %
  When $T_i$ invokes $\stmTryCommit$, transaction $T_j$ is committed.
  Thus, when $T_i$ executes \refline{stm:try:1} to call $\stmExtendFunction$, it fetches $(x_j,\clockOf{T_j})$ from $\locationOf{x}$.
  On the other hand, $(x_k, \clockOf{T_k}_f) \in \readSetOf{T_i}$ holds at that time.
  From \refprop{stm:1}, $\clockOf{T_j}_f \neq \clockOf{T_k}_f$.
  It follows that the test at \refline{stm:extend:3} fails, leading $T_j$ to abort at \refline{stm:try:2}.  
  
\end{proof}

\begin{theorem}
  \labtheo{spser}
  History $h$ belongs to $\SPSER$.
\end{theorem}

\begin{proof}
  \refprop{stm:2} tells us that if $T_i < T_j$ holds then $T_i$ commits before $T_j$.
  It follows that the strict serialization graph $(\committed{h},<)$ is acyclic.

  Let us now turn our attention to the second property of $\SPSER$.
  To this end, assume that a transaction $T_i$ aborts in $h$.
  For the sake of contradiction, consider that $T_i$ exhibits fair bindings and yet observes a non-strictly consistent snapshot.

  Applying the definition given in \refsection{criteria:model}, there exist transactions $T_j$ and $T_{k \neq j}$ such that $T_i \depends T_j$, $r_i(x_k)$ occurs in $h$ and $x_k \ll_h x_j$.  
  If $T_j \ll_{h} T_i$, then transaction $T_i$ cannot observe version $x_k$.
  Consequently, transaction $T_j$ is concurrent to $T_i$.
  In addition, there exists a transaction $T_l$ and some object $y$ such that $T_i$ performs $r_i(y_l)$ and $T_l \depends T_j$.

  Relation $<$ is acyclic, thus $x_k \neq y_l$ holds.  
  It remains to consider the following two cases:
  \begin{compactitem}
  \item ($r_i(y_l) \hb_h r_i(x_k)$)\\
    From \refprop{stm:2} and $T_l \depends T_j$, transaction $T_j$ is committed at the time $T_i$ reads object $x$.
    Contradiction.
  \item ($r_i(x_k) \hb_h r_i(y_l)$)\\
    We first argue that the timestamp fetches from $\locationOf{y}$ at the time $T_i$ executes \refline{stm:read:2} is greater than $\clockOf{T_i}$.
    \begin{proof}
      First of all, observe that $T_j$ is not committed at the time $T_i$ reads object $x$ (since $x_{k} \ll_h x_{j}$ holds).
      Denoting $q$ the process that executes $T_j$, $\clockOf{q} < \clockOf{T_j}_f$ is true when $T_i$ begins its execution at \refline{stm:start:1}.
      %%    
      Since transaction $T_l$ is concurrent to $T_i$ and $r_i(y_l)$ occurs, $T_i$ is bound to $T_l$ on $y$.
      Assume some object $z$ read by $T_i$ before $y$.
      Because the binding of $T_i$ to $T_l$ is fair, $T_l$ (or one of its dependencies) accesses $z$.
      As $h \in \RCAD$, if some transaction $T_r$ updates to version $z_r$ the object $z$ read by $T_i$ this transaction cannot be concurrent to $T_l$.
      Hence, applying \refprop{stm:1}, $\clockOf{T_r}_f < \clockOf{T_l}_f$ holds.
      This leas to the fact that $\clockOf{T_i} < \clockOf{T_l}_f$ at the time $T_i$ invokes \stmReadFunction on $x$.
      k
    \end{proof}
    Consequently, transaction $T_i$ invokes \stmExtendFunction at \refline{stm:refline:6}.
    Transaction $T_j$ is committed at that time.
    Since $T_j \depends T_l$, $T_j$ is also commited.
    Following a reasoning similar to the one given in \refprop{stm:3}, the test at \refline{stm:extend:3} fails.
  \end{compactitem}
\end{proof}

\paragraph{(Disjoint-access parallelism)}
The logical clocks used in \refalg{stm} can be shared or local to each process.
When they are are local, function $\clockOf{p}$ becomes injective.
Consider such a scenario and two transactions $T_i$ and $T_j$ that do not access on a common object.
If $T_i$ and $T_j$ are executed by distinct processes, then they do not contend on some base object in \refalg{stm}.
It follows that \refalg{stm} is strictly disjoint-access parallel.

