\section{Algorithm}
\labsection{stm}

In this section, we depict a locality-aware software transactional memory.
The pseudo-code of our construction is presented in \refalg{stm}.
This algorithm follows the general design of the lazy snapshot algorithm (LSA) of \citet{FelberFMR10}, replacing the central clock with a more flexible mechanism.

In what follows, we give an overview of the algorithm, present its internals then justify some design choices.
A correctness proofs follows.

\subsection{Overview}
\labsection{stm:overview}

\refalg{stm} depicts the pseudo-code of our implementation of the STM interface at some process $p$.
Our design follows a deferred update schema that consists in two steps.
A transaction first executes optimistically, buffering its updates.
Then at commit time the transaction is certified and, provided it commits, its updates are applied to the shared memory.

During the execution of a transaction, process $p$ checks that the registers accessed so far did not change.
Similarly to LSA, this check is lazily executed.
\refalg{stm} executes it only when a register appears to have been recently updated, or when transaction terminates.

\subsection{Tracking Time}
\labsection{stm:time}

%% define consistent clock as any mechanism from $H$ to (\tickSet,<)
%% satisfying for any two e, e' in $H$, $\hb e' \implies \Theta(e) < \Theta(e')$.

\refalg{stm} tracks time to compute how concurrent transactions interleave during an execution.
To this end, the algorithm makes use of logical clocks.
We model the interface of a \emph{logical clock} with two operations: $\cread$ returns a value in $\naturalSet$, and $\cadv(v \in \naturalSet)$ updates the clock with value $v$.
The sequential specification of a logical clock guarantees a single property, that the time flows forward:
\begin{inparaenum}
\item[\emph{(Time monoticity)}]
  A read operation always returns at least the greatest value to which the clock advanced so far.
  Formally, for every history $h$, $(\responseAny{\cread}{v} \in h) \implies (v \geq \max{(\{u : \cadv(u) \hb_h \cread \} \union \{0\})})$.
\end{inparaenum}

\refalg{stm} associates logical clocks with both processes and transactions.
To retrieve the clock associated with some object $i$, our algorithm uses function $\clockOf{i}$.
Notice that in the pseudo-code, when it is clear from the context, 
we write $\clockOf{i}$ as a shorthand for $\clockOf{i}.\mathit{read}()$.

The clock associated with a transaction is always local (\refline{stm:var:1}).
In the case of a process, it might be shared or not (\refline{stm:var:2}).
The flexibility of our design comes from this locality choice for \clockOf{p}.
When the clock is shared, it is linearizable.
To implement an (obstruction-free) linearizable clock we proceeds as follows.
\begin{construction}
  Let $x$ be a shared register initialized to $0$.
  When $\cread$ is called, we return the value stored in $x$.
  Upon executing $\cadv(v)$, we fetch the value stored in $x$, say $u$.
  If $v > u$ holds, we execute a compare-and-swap to replace $u$ with $v$; 
  otherwise the operation returns.
  If the compare-and-swap fails, the previous steps are retried.
\end{construction}

\input{algorithms/stm.tex}

\subsection{Details}
\labsection{stm:detail}

In \refalg{stm}, each register $x$ has a \emph{location} in the shared memory, denoted $\locationOf{x}$.
This location stores a pair $(t,d)$, where $t \in \naturalSet$ is a \emph{timestamp}, and $d$ is the actual content of $x$ as seen by transactions.
We name a pair $(t,d)$ a \emph{version} of the register $x$.
Since the location of register $x$ is unique, a single version of register $x$ may exist at a time in the memory.
As usual, we asume some transaction $\transInit$ that intializes for every register $x$ the location $\locationOf{x}$ to $(0,\bot)$.
Furthermore, we consider that each register $x$ is atomic.

\refalg{stm} associates each register with a lock.
To manipulate the lock-related functions of register $x$, 
a process $p$ employs appropriately the functions $\lock{x}$, $\isLocked{x}$ and $\unlock{x}$.

For every transaction $T$ submitted to the system, \refalg{stm} maintains three local data structures:
\begin{inparaenum}[]
\item $\clockOf{T}$ is the logical clock of transaction $T$,
\item $\readSetOf{T}$ is a map that contains its \emph{read set}, and 
\item $\writeSetOf{T}$ is another map that stores the \emph{write set} of $T$.
\end{inparaenum}
\refalg{stm} updates incrementally $\readSetOf{T}$ and $\writeSetOf{T}$ over the course of the execution.
The read set serves to check that the view of the shared memory, or \emph{snpashot}, seen by the transaction is consistent.
The write set buffers updates.
In detail, the execution of a transaction $T$ proceeds as follows.

\begin{itemize}
\item[-] %
  When $T$ starts its execution, \refalg{stm} initializes $\clockOf{T}$ to the value of $\clockOf{p}$, then both $\readSetOf{T}$ and $\writeSetOf{T}$ to $\emptySet$ (\reflines{stm:start:1}{stm:start:3}).
\item[-] %
  When $T$ accesses a register $x$, if $x$ was previously written, its value is returned (\refline{stm:read:1}).
  Otherwise, \refalg{stm} fetches atomically the version $(d,t)$, as seen in location $\locationOf{x}$.
  Then, the algorithm checks that 
  \begin{inparaenum}
  \item no lock is held on $x$, and 
  \item in case $x$ was previously accessed, that $T$ observes the same version.
  \end{inparaenum}
  If one of these two conditions fails, \refalg{stm} aborts transaction $T$ (\refline{stm:read:5}).
  The algorithm then checks that the timestamp $t$ associated to the content $d$ is smaller than the clock of $T$.
  In case this does not hold (\refline{stm:read:6}), \refalg{stm} tries extending the snapshot of $T$ by calling function $\stmExtend{}$.
  This function returns $\true$ when the versions previously read by $T$ are still valid.
  In which case, $\clockOf{T}$ is updated to the value $t$.
  If \refalg{stm} succeeds in extending (if needed) the snapshot of $T$, $d$ is returned and the read set of $T$ updated accordingly;
  otherwise transaction $T$ is aborted (\refline{stm:read:7}).
\item[-] %
  Upon executing a write request on behalf of $T$ to some register $x$, \refalg{stm} takes the lock associated with $x$ (\refline{stm:write:1}), and in case of success, it buffers the update value $d$ in $\writeSetOf{T}$ (\refline{stm:write:6}).
  The timestamp $t$ of $x$ at the time \refalg{stm} takes the lock serves two purposes.
  First, \refalg{stm} checks that $t$ is lower than the current clock of $T$, and if not $T$ is extended (\refline{stm:write:4}).
  Second, it is saved in \writeSetOf{T} to ensure that at commit time the timestamp of the version of $x$ written by $T$ is greater than $t$.
\item[-] %
  When $T$ requests to commit, \refalg{stm} certifies the read set by calling function $\stmExtend{}$ with the clock of $T$ (\refline{stm:try:1}).
  If this test succeeds, transaction $T$ commits (\reflines{stm:commit:1}{stm:commit:6}).
  In such a case, \clockOf{T} ticks to reach its final value (\refline{stm:commit:1}).
  By construction, this value is greater than the clock of process $p$ at the time transaction $T$ started (\refline{stm:start:1}), as well as all the timestamps of all the versions read or written by $T$ (\reflinestwo{stm:read:5}{stm:write:4}).
  \refalg{stm} updates the clock of $p$ with the final value of \clockOf{T} (\refline{stm:commit:2}), then it updates the items written by $T$ with their novel versions (\refline{stm:commit:4}).
\end{itemize}

\refalg{stm} replaces the global clock usually employed in STM architectures with a locality-aware clock.
When \clockOf{p} is local to each process, \refalg{stm} ensures strict disjoint access parallelism (DAP) \cite{Attiya2015}.
More formally, this means that two transaction $T$ and $T'$ access concurrently a low-level object at the implementation side only if the two transactions actually contend on some high-level object at the interface (here registers).
Provided the workload is parallel, DAP ensures the scalability of \refalg{stm}.
We assess empirically this claim in \refsection{evaluation}.

On the other hand, if processes need to synchronize too often, maintaining consistency among the various clocks is expensive.
In this situation, it might be of interest to find a compromise between the cost of cache coherency and the need for synchronization.
For instance, in a NUMA architecture, \refalg{stm} may assign a common clock per hardware socket.
Upon a call to $\clockOf{p}$, the algortihm returns the clock defined for the socket in which the processor executing process $p$ resides.

\subsection{Guarantees}
\labsection{stm:guarantees}

In this section, we prove the different properties \refalg{stm} provides.
First, we show that our STM design is weakly progressive and strictly serializable.
Then, we prove that, when $\clockOf{p}$ is local, \refalg{stm} is strictly disjoint-parallel.

\paragraph{(Weak-progress)}
A transaction executes under \emph{weak progressiveness} \cite{Guerraoui:2009}, or equivalently it is \emph{weakly progressive}, when it aborts only if it encounters a conflicting transaction.
By extension, an STM is weakly progressive when it only produces histories during which transactions are weakly-progressive.
We prove that this property holds for \refalg{stm}.

In \refalg{stm}, a transaction $T$ aborts either at \refline{stm:read:5}, \ref{line:alg:stm:read:7}, \ref{line:alg:stm:write:2}, \ref{line:alg:stm:write:5}, or \ref{line:alg:stm:try:2}.
We observe that in such a case either $T$ observes an item $x$ locked, or that the timestamp associated with $x$ has changed.
It follows that if $T$ aborts then it observes a conflict with a concurrent transaction.
From which we deduce that it is executing under weak progressiveness.

\paragraph{(Strict serializability)}
Consider some run \run of \refalg{stm}, and let $\hat{h}$ be the history indeuced by \run.
Every function in \refalg{stm} is wait-free.
As a consequence, we may consider without lack of generality that $\hat{h}$ is complete, i.e., every transaction executed in $\hat{h}$ terminates with either a commit or an abort event.
Hereafter, $h$ denotes the sub-history of $\hat{h}$ that only contains the transactions committed in $\hat{h}$.

Consider some version order $\ll_h$ for $h$.
We note $<$ the relations over the transactions in $h$ induced by $\ll_h$; namely:
\begin{displaymath}
  \begin{array}{l}
    T_i < T_{j \neq i}  \equaldef \\
    \lor~ T_i \hb_h T_j {\hspace{16.8em}\text{(1)}} \\
    \lor~ \exists x : \lor~ r_j(x_i) \in h {\hspace{13.3em}\text{(2)}} \\
    \hspace{2.9em}\lor~ \exists T_k : x_k \ll_{h,x} x_j \land \lor~T_k = T_i {\hspace{5em}\text{(3)}} \\
    \hspace{12.2em} \lor~ r_i(x_k) \in h {\hspace{3.9em}\text{(4)}}
  \end{array}
\end{displaymath}
In the above definition, (1) is a real-time order between $T$ and $T'$, (2) a read-write dependency, (3) a version ordering, and (4) an anti-dependency.

For each register $x$, we consider the version order $\ll_{h,x}$ that corresponds to the order in which writes are linearized on $x$ in $\rho$.
Below, we prove that $<$ is acyclic for this definition of $\ll$, leading to the fact that $h$ is strictly serializable \cite{adyaPHD,pap79}.

\begin{proposition}
  \labprop{sser:1}
  Consider two transactions $T_i$ and $T_{j \neq i}$ in $h$ such that $T_i < T_j$.
  If $T_i$ and $T_j$ transactions conflict then $T_i$ invokes $\stmCommitFunction$ before $T_j$ in $h$.
\end{proposition}

\begin{proof}
  Assume that $T_i$ and $T_j$ conflict of some register $x$.
  We examine in order each of the four cases defining relation $<$.
  \begin{compactitem}
  \item[(1)]
    This case is immediate.
  \item[(2)]
    Transaction $T_j$ reads the version of $x$ written by transaction $T_i$, that is $r_i(x_j) \in h$ holds.
    Before committing, $T_j$ invokes \stmExtendFunction at \refline{stm:try:1}.
    Since $T_j$ commits in $h$, it should retrieve $(x_i,\msgAny)$ from $\locationOf{x}$ when executing \refline{stm:extend:2}.
    Hence, transacion $T_i$ has already exeecuted \emph{stm:commit:4} for register $x$.
    It follows that $T_i$ invoke $\stmCommitFunction$ before transaction $T_j$ in history $h$.
  \item[(3)]
    By definition of $\ll_{h,x}$, the write of version $x_i$ is linearized before the write of version $x_j$ in $\rho$.
    At the time, $T_i$ executes this write, the transaction must own a lock on register $x$ (\refline{stm:commit:4}).
    The register is then unlocked by transaction $T_i$ (\refline{stm:commit:5}).
    As a consequence, transaction $T_i$ takes a lock on register $x$ after $T_i$ invokes operation $\stmCommitFunction$.
    From which it follows that the claim holds.
  \item[(4)]
    Consider the time at which $T_i$ calls \stmExtendFunction at \refline{stm:try:1}.
    Since $T_i$ commits, $T_j$ cannot hold the lock when $T_i$ executes \refline{stm:extend:2}.
    For the sake of contradiction, then assume that $T_j$ invokes $\stmTryCommit$ before $T_i$.
    When $T_j$ invokes $\stmTryCommit$, the transaction holds a lock on $x$.
    This lock is released at \refline{stm:commit:5} after the write of version $x_j$ occurs.    
    It follows that $T_i $ reads register $x$ at \refline{stm:extend:5} after the write of version $x_j$ occurs.
    Now, from the definition of $\ll_{h,x}$ the write of version $x_k$ takes place before the write of version $x_j$ in $\rho$.
    Since $T_i$ reads version $x_k$ in $h$, a pair $(\msgAny,x_k)$ is in $\readSetOf{T_i}$.    
    As a consequence, when $T_i$ executes \refline{stm:extend:5} the 
    
    
    
    It follows, that the transaction has already 
    
  \end{compactitem}
  
\end{proof}

\begin{proposition}  
  \labprop{sser:2}
  Relation $((\union_{x} \stmPrec{x}) ~\union \hb_h)$ is acyclic.
\end{proposition}

\begin{proof}
  As a starter, observe that if transaction $T$ reads register, then $\readSetOf{T}[x] < \clockOf{T}_f$ holds.
  This observation tell us that a chain $(T_i \stmPrec{x} T_j \stmPrec{y} T_k)$ implies $(\clockOf{T_i}_f < \clockOf{T_k}_f)$.
  From which we deduce that claim $(\union_{x} \stmPrec{x})$ is acyclic.
  Then, \refprop{sser:1} tell us that if $T_i \stmPrec{x} T_j$ holds then $T_j$ cannot commit before $T_i$.
  It follows that relation $((\union_{x} \stmPrec{x}) ~\union \hb_h)$ is acyclic.  
\end{proof}

The above proposition leads immediately to the following theorem.

\begin{theorem}
  \labtheo{ss}
  History $h$ is strictly serializable.
\end{theorem}

\begin{proof}
  some details
\end{proof}

\paragraph{(Disjoint-access parallelism)}
The logical clocks used in \refalg{stm} can be shared or local to each process.
When they are are local, function $\clockOf{p}$ becomes injective.
Consider such a scenario and two transactions $T_i$ and $T_j$ that do not access on a common register.
If $T_i$ and $T_j$ are executed by distinct processes, then they do not contend on some low-level object in \refalg{stm}.
It follows that \refalg{stm} is strictly disjoint-access parallel.

