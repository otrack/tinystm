\section{Algorithm}
\labsection{stm}

In this section, we present a transactional memory that attains $\SPSER$.
Our construction is weakly-progressive, that is, it aborts a transaction only if it encounters a concurrent conflicting transaction.
Reads operations are invisible, that is they do not modify any base object of the implementation.
Moreover, and contrary to several existing TM designs, our design does not require a global clock.

We first give an overview of the algorithm, present its internals and justify some design choices.
A correctness proofs follows.
We close this section with discussing the parameters of our algorithm and possible.
In particular, we explain how to tailor it to be disjoint-access parallel.

\subsection{Overview}
\labsection{stm:overview}

\refalg{stm} depicts the pseudo-code of our construction of the STM interface at some process $p$.
Our design follow the general approach of the lazy snapshot algorithm (LSA) of \citet{FelberFMR10}, replacing the central clock with a more flexible mechanism.
\refalg{stm} employs a deferred update schema that consists in two steps.
A transaction first executes optimistically, buffering its updates.
Then, at commit time, the transaction is certified and if it commits its updates are applied to the shared memory.

During the execution of a transaction, a process checks that the objects accessed so far did not change.
Similarly to LSA, this check is lazily executed.
More specifically, \refalg{stm} executes it only if a shared object appears to have been recently updated, or when the transaction terminates.

\subsection{Tracking Time}
\labsection{stm:time}

\refalg{stm} tracks time to compute how concurrent transactions interleave during an execution.
To this end, the algorithm makes use of logical clocks.
We model the interface of a \emph{logical clock} with two operations: $\cread$ returns a value in $\naturalSet$, and $\cadv(v \in \naturalSet)$ updates the clock with value $v$.
The sequential specification of a logical clock guarantees a single property, that the time flows forward:
\begin{inparaenum}
\item[\emph{(Time monoticity)}]
  A read operation always returns at least the greatest value to which the clock advanced so far.
  Formally, for every history $h$, $(\responseAny{\cread}{v} \in h) \implies (v \geq \max{(\{u : \cadv(u) \hb_h \cread \} \union \{0\})})$.
\end{inparaenum}

\refalg{stm} associates logical clocks with both processes and
transactions.  To retrieve the clock associated with some object $i$,
the algorithm uses function $\clockOf{i}$.  Notice that in the
pseudo-code, when it is clear from the context, we write $\clockOf{i}$
as a shorthand for $\clockOf{i}.\mathit{read}()$.

The clock associated with a transaction is always local (\refline{stm:var:1}).
In the case of a process, it might be shared or not (\refline{stm:var:2}).
The flexibility of our design comes from this locality choice for \clockOf{p}.
When the clock is shared, it is linearizable.
To implement an (obstruction-free) linearizable clock we employ the following common approach:
\begin{construction}
  Let $x$ be a shared register initialized to $0$.
  When $\cread$ is called, we return the value stored in $x$.
  Upon executing $\cadv(v)$, we fetch the value stored in $x$, say $u$.
  If $v > u$ holds, we execute a compare-and-swap to replace $u$ with $v$; 
  otherwise the operation returns.
  If the compare-and-swap fails, the previous steps are retried.
\end{construction}

\input{algorithms/stm.tex}

\subsection{Details}
\labsection{stm:details}

In \refalg{stm}, each object $x$ has a \emph{location} in the shared memory, denoted $\locationOf{x}$.
This location stores a pair $(t,d)$, where $t \in \naturalSet$ is a \emph{timestamp}, and $d$ is the actual content of $x$ as seen by transactions.
For simplicity, we shall name hereafter a pair $(t,d)$ a \emph{version} of object $x$.
Since the location of object $x$ is unique, a single version of object $x$ may exist at a time in the memory.
As usual, we asume some transaction $\transInit$ that intializes for every object $x$ the location $\locationOf{x}$ to $(0,\bot)$.
Furthermore, we consider that each read or write operation to some location $\locationOf{x}$ is atomic.

\refalg{stm} associates a lock to each object.
To manipulate the lock-related functions of object $x$, 
a process $p$ employs appropriately the functions $\lock{x}$, $\isLocked{x}$ and $\unlock{x}$.

For every transaction $T$ submitted to the system, \refalg{stm} maintains three local data structures:
\begin{inparaenumorig}[]
\item $\clockOf{T}$ is the logical clock of transaction $T$;
\item $\readSetOf{T}$ is a map that contains its read set; and 
\item $\writeSetOf{T}$ is another map that stores the write set of $T$.
\end{inparaenumorig}
\refalg{stm} updates incrementally $\readSetOf{T}$ and $\writeSetOf{T}$ over the course of the execution.
The read set serves to check that snpashot of the shared memory as seen by the transaction is strictly consistent.
The write set buffers updates.
With more details, the execution of a transaction $T$ proceeds as follows.

\begin{itemize}
\item[-] %
  When $T$ starts its execution, \refalg{stm} initializes $\clockOf{T}$ to the smallest value of $\clockOf{q}$ for any process $q$ executing the TM.
  Then, both $\readSetOf{T}$ and $\writeSetOf{T}$ are set to $\emptySet$.
\item[-] %
  When $T$ accesses a shared object $x$, if $x$ was previously written, its value is returned (\refline{stm:read:1}).
  Otherwise, \refalg{stm} fetches atomically the version $(d,t)$, as seen in location $\locationOf{x}$.
  Then, the algorithm checks that 
  \begin{inparaenum}
  \item no lock is held on $x$, and 
  \item in case $x$ was previously accessed, that $T$ observes the same version.
  \end{inparaenum}
  If one of these two conditions fails, \refalg{stm} aborts transaction $T$ (\refline{stm:read:5}).
  The algorithm then checks that the timestamp $t$ associated to the content $d$ is smaller than the clock of $T$.
  In case this does not hold (\refline{stm:read:6}), \refalg{stm} tries extending the snapshot of $T$ by calling function $\stmExtend{}$.
  This function returns $\true$ when the versions previously read by $T$ are still valid.
  In which case, $\clockOf{T}$ is updated to the value $t$.
  If \refalg{stm} succeeds in extending (if needed) the snapshot of $T$, $d$ is returned and the read set of $T$ updated accordingly;
  otherwise transaction $T$ is aborted (\refline{stm:read:7}).
\item[-] %
  Upon executing a write request on behalf of $T$ to some object $x$, \refalg{stm} takes the lock associated with $x$ (\refline{stm:write:1}), and in case of success, it buffers the update value $d$ in $\writeSetOf{T}$ (\refline{stm:write:6}).
  The timestamp $t$ of $x$ at the time \refalg{stm} takes the lock serves two purposes.
  First, \refalg{stm} checks that $t$ is lower than the current clock of $T$, and if not $T$ is extended (\refline{stm:write:4}).
  Second, it is saved in \writeSetOf{T} to ensure that at commit time the timestamp of the version of $x$ written by $T$ is greater than $t$.
\item[-] %
  When $T$ requests to commit, \refalg{stm} certifies the read set by calling function $\stmExtend{}$ with the clock of $T$ (\refline{stm:try:1}).
  If this test succeeds, transaction $T$ commits (\reflines{stm:commit:1}{stm:commit:6}).
  In such a case, \clockOf{T} ticks to reach its final value (\refline{stm:commit:1}).
  By construction, this value is greater than the timestamps of all the versions read or written by $T$ (\reflinestwo{stm:read:5}{stm:write:4}).
  \refalg{stm} updates the clock of $p$ with the final value of \clockOf{T} (\refline{stm:commit:2}), then it updates the items written by $T$ with their novel versions (\refline{stm:commit:4}).
\end{itemize}

\subsection{Guarantees}
\labsection{stm:guarantees}

In this section, we assess the core properties of \refalg{stm}.
First, we show that our TM design is weakly progressive, i.e., that the algorithm aborts a transaction only if it encounters a concurrent conflicting transaction.
Then, we prove that \refalg{stm} is stricter serializable.

\paragraph{(Weak-progress)}
A transaction executes under \emph{weak progressiveness} \cite{Guerraoui:2009}, or equivalently it is \emph{weakly progressive}, when it aborts only if it encounters a conflicting transaction.
By extension, an STM is weakly progressive when it only produces histories during which transactions are weakly-progressive.
We prove that this property holds for \refalg{stm}.

In \refalg{stm}, a transaction $T$ aborts either at \refline{stm:read:5}, \ref{line:alg:stm:read:7}, \ref{line:alg:stm:write:2}, \ref{line:alg:stm:write:5}, or \ref{line:alg:stm:try:2}.
We observe that in such a case either $T$ observes an item $x$ locked, or that the timestamp associated with $x$ has changed.
It follows that if $T$ aborts then it observes a conflict with a concurrent transaction.
From which we deduce that it is executing under weak progressiveness.

\paragraph{(Stricter serializability)}
Consider some run $\run$ of \refalg{stm}, and let $h$ be the history produced in \run.
At the light of its pseudo-code, every function defined in \refalg{stm} is wait-free.
As a consequence, we may consider without lack of generality that $h$ is complete, i.e., every transaction executed in $h$ terminates with either a commit or an abort event.
In what follows, we define that $\ll_h$ as the order in which writes to the object locations are linearized in $\rho$.
We first prove that $<$ is acyclic for this definition of $\ll_h$.
Then, we show that, if a transaction does not exhibit any unfair binding, then it observes a strictly consistent snapshot.
For some transaction, we shall note $\clockOf{T_i}_f$ the final value of $\clockOf{T}$.

\begin{proposition}
  \labprop{stm:1}
  Consider two transactions $T_i$ and $T_{j \neq i}$ in $h$.
  If either $T_i \depends T_j$ or  $x_j \ll_h x_i$ holds, then $\clockOf{T_i}_f \geq \clockOf{T_j}_f$ is true.
  In addition, if transaction $T_i$ commits then the ordering is strict, i.e., $\clockOf{T_i}_f > \clockOf{T_j}_f$.
\end{proposition}

\begin{proof}

  In each of the two cases, we prove that $\clockOf{T_i}_f \geq \clockOf{T_i}_f$ holds before transaction $T_i$ commits.
  \begin{itemize}
  \item[($T_i \depends T_j$)]
    Let $x$ be an object such that $r_i(x_j)$ occurs in $h$.
    Since transaction $T_i$ reads version $x_j$, transaction $T_j$ commits.
    We observe that $T_j$ writes version $x_j$ together with $\clockOf{T_j}_f$ at $\locationOf{x}$ when it commits (\refline{stm:commit:4}).
    As a consequence, when transaction $T_i$ returns version $x_i$ at \refline{stm:read:9}, it assigns $\clockOf{T_j}_f$ to $t$ before at \refline{stm:read:2}.
    The condition at \refline{stm:read:6} implies that either $\clockOf{T_i} \geq t$ holds, or a call to $\stmExtend{T_i,t}$ occurs.
    In the latter case, transactino $T_i$ executes \refline{stm:extend:5}, advancing its clock up to the value of $t$.
  \item[($x_j \ll_h x_i$)]
    By definition, relation $\ll_h$ forms a total order over all versions of $x$.
    Thus, we may reason by induction, considering that $x_i$ is immediately after $x_j$ in the order $\ll_h$.
    When $T_j$ returns from $w_j(x_j)$ at \refline{stm:write:6}, it holds a lock on $x$.
    This lock is released at \refline{stm:commit:5} after writing to $\locationOf{x}$.
    As $\ll_h$ follows the linearization order, $T_i$ executes \refline{stm:write:1} after $T_j$ wrote $(x_j, \clockOf{T_j}_f)$ to $\locationOf{x}$.
    Location $\locationOf{x}$ is not updated between $x_j$ and $x_i$.
    Hence, after$T_i$ executes \refline{stm:write:4}, $\clockOf{T_i} \geq \clockOf{T_j}$ holds.
  \end{itemize}
  Since a clock is monotonic, the relation holds forever.
  Then, if transaction $T_i$ commits, it must executes \refline{stm:commit:1}, leading to $\clockOf{T_i}_f > \clockOf{T_i}_f$.
\end{proof}

\begin{proposition}
  \labprop{stm:2}
  History $h$ does not exhibit any RC-anti-dependencies ($h \notin \RCAD$)
\end{proposition}

\begin{proof}
  Consider $T_i$, $T_j$ and $T_k$ such that $r_i(x_k), w_j(x_j) \in h$, $x_k \ll_h x_j$ and $T_j$ commits before $T_i$.
  %
  When $T_j$ invokes $\stmCommitFunction$, it holds a lock on $x$.
  This lock is released at \refline{stm:commit:5} after version $x_j$ is written at location $\locationOf{x}$.
  %
  Then, consider the time at which $T_i$ invokes $\stmTryCommitFunction$.
  The call at \refline{stm:try:1} leads to fetching $\locationOf{x}$ at \refline{stm:extend:2}.
  Since $T_i$ reads version $x_k$ in $h$, a pair $(x_k,\clockOf{T_k}_f)$ is in $\readSetOf{T_i}$.
  From the definition of $\ll_h$ the write of $(x_k,\clockOf{T_k}_f)$ takes place before the write of version $(x_j,\clockOf{T_j}_f)$ in $\rho$.
  Hence, $\locationOf{x}$ does not contain anymore $(x_k,\clockOf{T_k}_f)$
  Applying \refprop{stm:1}, $T_i$ executes \refline{stm:extend:4} and aborts at \refline{stm:try:3}.
\end{proof}

\begin{proposition}
  \labprop{stm:3}
  Consider two transactions $T_i$ and $T_{j \neq i}$ in $\committed{h}$.
  If $T_i < T_j$ holds, transaction $T_i$ invokes $\stmCommitFunction$ before transaction $T_j$ in $h$.
\end{proposition}

\begin{proof}
  Assume that $T_i$ and $T_j$ conflict of some object $x$.
  We examine in order each of the four cases defining relation $<$.
  \begin{compactitem}
  \item ($T_i \hb_h T_j$)\\
    This case is immediate.
  \item ($\exists x : r_j(x_i) \in h$)\\
    Before committing, $T_j$ invokes \stmExtendFunction at \refline{stm:try:1}.
    Since $T_j$ commits in $h$, it should retrieve $(x_i,\msgAny)$ from $\locationOf{x}$ when executing \refline{stm:extend:2}.
    Hence, transaction $T_i$ has already exeecuted \refline{stm:commit:4} on object $x$.
    It follows that $T_i$ invokes $\stmCommitFunction$ before transaction $T_j$ in history $h$.
  \item ($\exists x : x_i \ll_h x_j$)\\
    By definition of $\ll_h$, the write of version $x_i$ is linearized before the write of version $x_j$ in $\rho$.
    After $T_i$ returns from $w_i(x_i)$, it owns a lock on object $x$ (\refline{stm:commit:4}).
    The object is then unlocked by transaction $T_i$ at \refline{stm:commit:5}.
    As a consequence, transaction $T_i$ takes a lock on object $x$ after $T_i$ invokes operation $\stmCommitFunction$.
    From which it follows that the claim holds.
  \item ($\exists x, T_k : x_k \ll_x x_j \land r_i(x_k)$)\\
    Follows from \refprop{stm:2}.
  \end{compactitem}
  
\end{proof}

\begin{theorem}
  \labtheo{spser}
  History $h$ belongs to $\SPSER$.
\end{theorem}

\begin{proof}
  \refprop{stm:3} tells us that if $T_i < T_j$ holds then $T_i$ commits before $T_j$.
  It follows that the $\SSG(h,\ll_h)$ is acyclic.

  Let us now turn our attention to the second property of $\SPSER$.
  Assume that a transaction $T_i$ aborts in $h$.
  For the sake of contradiction, consider that $T_i$ exhibits fair bindings and yet that it observes a non-strictly consistent snapshot.

  Applying the definition given in \refsection{criteria:model}, there exist transactions $T_j$ and $T_k$ such that $T_i \depends T_j$, $r_i(x_k)$ occurs in $h$ and $x_k \ll_h x_j$.  
  Applying \refprop{stm:3}, if $T_j \hb_{h} T_i$ holds, transaction $T_i$ cannot observe version $x_k$.
  Thus, transaction $T_j$ is concurrent to $T_i$.
  Moreover, by definition of $T_i \depends T_j$, there exist a transaction $T_l$ (possibly, $T_j$) and some object $y$ such that $T_i$ performs $r_i(y_l)$ and $T_l \depends T_j$.
  In what follows, we prove that $T_i$ aborts before returning $y_l$.
  
  For starter, relation $<$ is acyclic, thus $x_k \neq y_l$ holds.  
  It then remains to investigate the following two cases:
  \begin{compactitem}
  \item ($r_i(y_l) \hb_h r_i(x_k)$)\\
    From \refprop{stm:3} and $T_l \depends T_j$, transaction $T_j$ is committed at the time $T_i$ reads object $x$.
    Contradiction.
  \item ($r_i(x_k) \hb_h r_i(y_l)$)\\
    We first argue that, at the time $T_i$ executes \refline{stm:read:2}, the timestamp fetches from $\locationOf{y}$ is greater than $\clockOf{T_i}$.
    \begin{proof}
      First of all, observe that $T_j$ is not committed at the time $T_i$ reads object $x$ (since $x_{k} \ll_h x_{j}$ holds).
      Hence, denoting $q$ the process that executes $T_j$, $\clockOf{q} < \clockOf{T_j}_f$ is true when $T_i$ begins its execution at \refline{stm:start:1}.
      From the pseudo-code at \refline{stm:start:1}, $\clockOf{T_i} < \clockOf{T_j}_f$ holds at the start of $T_i$.
      %
      Because $T_j$ is concurrent to $T_i$, $T_l$ is also concurrent to $T_i$ by \refprop{stm:3}.
      Thus, as $r_i(y_l)$ occurs, $T_i$ is bound to $T_l$ on $y$.
      Now, consider some object $z$ read by $T_i$ before $y$, and name $z_r$ the version read by $T_i$.
      Since the binding of $T_i$ to $T_l$ is fair, $T_l$ accesses $z$.
      As $h \notin \RCAD$, transaction $T_r$ cannot update object $z$ concurrently to $T_l$.
      Hence, applying \refprop{stm:1}, $\clockOf{T_r}_f < \clockOf{T_l}_f$ holds.
      As a consequence, the relation $\clockOf{T_i} < \clockOf{T_l}_f$ is true.
    \end{proof}
    From what precedes, transaction $T_i$ invokes \stmExtendFunction at \refline{stm:read:6}.
    We know that transaction $T_j$ is committed at that time (since $T_l$ is committed and $T_l \depends T_j$ holds).
    Thus, the test at \refline{stm:extend:3} fails and $T_i$ aborts before returning $y_l$.
  \end{compactitem}
\end{proof}

\subsection{Discussion}
\labsection{stm:discussion}

\refalg{stm} replaces the global clock usually employed in STM architectures with a more flexible mechanism.
For some process $p$, \clockOf{p} can be local to $p$, shared across a subset of the processes, or even all of them.

If processes need to synchronize too often, maintaining consistency among the various clocks is expensive.
In this situation, it might be of interest to find a compromise between the cost of cache coherency and the need for synchronization.
For instance, in a NUMA architecture, \refalg{stm} may assign a clock per hardware socket.
Upon a call to $\clockOf{p}$, the algortihm returns the clock defined for the socket in which the processor executing process $p$ resides.

On the other hand, when the processes use a global clock, \refalg{stm} boils down to the original code of TinySTM \cite{}.
In this case, a read-only transaction alayws sees a strictly consistent snapshot and it may commit right after a call to $\stmTryCommitFunction$, i.e., without checking its snapshot at \refline{stm:abort:1}.

A last observation is that our algorithm works even if one of the processes takes no step.
This implies that the call to process clocks (at \reflinestwo{stm:start:1}{stm:commit:2}) is strictly speaking unecessary, and it can be skipped without impacting the correctness of \refalg{stm}.
Clocks are in fact only used to avoid extending the snapshot at each read step (contrary to, e.g., \cite{}).
In such a case, \refalg{stm} is disjoint-access parallel since in a scenario where two transactions access disjoint objects, they do not contend on any base object of the implementation.
